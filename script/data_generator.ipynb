{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os,random,networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file(path, content):\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    with open(path, 'a') as out:\n",
    "        out.write(content+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lines(file_path):\n",
    "    array = []\n",
    "    with open(file_path, \"r\") as ins:\n",
    "        for line in ins:\n",
    "            line = line.replace(\"\\n\",\"\")\n",
    "            if len(line)>0:\n",
    "                array.append(line)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_user_label_file(node_size, label_cat, train_size, user_all_file, user_truth_file, user_train_file, user_target_file):\n",
    "    user_train = ''\n",
    "    user_truth = ''\n",
    "    user_target = ''\n",
    "    user_all = ''\n",
    "    for i in range (node_size):\n",
    "        for label in label_cat:\n",
    "            label_size = len(label)\n",
    "            index = random.randint(1, label_size-1)\n",
    "            user_all+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[index]+'\\n'\n",
    "            if i>train_size:\n",
    "                j=1\n",
    "                while j<label_size:\n",
    "                    if j==index:\n",
    "                        user_truth+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[index]+'\\t'+'1.0'+'\\n'\n",
    "                    else:\n",
    "                        user_truth+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[j]+'\\t'+'0.0'+'\\n'\n",
    "                    user_target+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[j]+'\\n'\n",
    "                    j+=1\n",
    "            else:\n",
    "                j=1\n",
    "                while j<label_size:\n",
    "                    if j==index:\n",
    "                        user_train+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[index]+'\\t'+'1.0'+'\\n' \n",
    "                    else:\n",
    "                        user_train+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[j]+'\\t'+'0.0'+'\\n' \n",
    "                    j+=1\n",
    "    save_file(user_train_file, user_train)\n",
    "    save_file(user_truth_file, user_truth)\n",
    "    save_file(user_target_file, user_target)\n",
    "    save_file(user_all_file, user_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_predictor(source, accuracy_label_cat, user_label_file, label_cat_info, predictor_file):\n",
    "    lines = read_lines(user_label_file)\n",
    "    user_txt = ''\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        user = info[0]\n",
    "        cat = info[1]\n",
    "        label = info[2]\n",
    "        label_cat, accuracy = find_label_cat(accuracy_label_cat, cat, label, label_cat_info)\n",
    "        predict = random.random() \n",
    "        if predict>accuracy:\n",
    "            index = 1\n",
    "            while label_cat[index]==label:\n",
    "                index+=1\n",
    "            label = label_cat[index]\n",
    "        user_txt+= source+'\\t'+user+'\\t'+label_cat[0]+ '\\t'+label+'\\t'+'1.0'+'\\n'\n",
    "    save_file(predictor_file, user_txt)\n",
    "    return user_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_label_cat(accuracy_label_cat, cat, label, label_cat_info):\n",
    "    notFind = True\n",
    "    index = 0\n",
    "    while notFind:\n",
    "        info = accuracy_label_cat[index]\n",
    "        if info[1]==cat:\n",
    "            notFind = False\n",
    "            accuracy = info[0]\n",
    "            label_cat = label_cat_info[index]\n",
    "        else:\n",
    "            index+=1\n",
    "    return label_cat, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_links(node_size, user_link_file):\n",
    "    link_txt = ''\n",
    "    edges = create_synthetic_graph(node_size)\n",
    "    for edge in edges:\n",
    "        link_txt+= 'u'+str(edge[0])+'\\t'+'u'+str(edge[1])+'\\t'+'1.0'+'\\n'\n",
    "    save_file(user_link_file, link_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_synthetic_graph(node_size):\n",
    "    m = 6\n",
    "    p = 0.3 \n",
    "    graph = networkx.powerlaw_cluster_graph(node_size, m, p, seed=None)\n",
    "    return graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_likes(user_label_file, likes_label_cat, label_cat, likes_file):\n",
    "    lines = read_lines(user_label_file)\n",
    "    likes_txt = ''\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        user = info[0]\n",
    "        cat = info[1]\n",
    "        label = info[2]\n",
    "        item = get_item(likes_label_cat,label_cat, cat, label)\n",
    "        likes_txt += user+'\\t'+item+'\\t'+'1.0'+'\\n'\n",
    "    save_file(likes_file, likes_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item(likes_label_cat, label_cat, cat, label):\n",
    "    notFind = True\n",
    "    cat_index = 0\n",
    "    item = ''\n",
    "    while notFind:\n",
    "        items = likes_label_cat[cat_index]\n",
    "        if items[1]==cat:\n",
    "            prob = items[0]\n",
    "            notFind = False\n",
    "            label_index = 1\n",
    "            label_not_find = True\n",
    "            labels = label_cat[cat_index]\n",
    "            while label_not_find:\n",
    "                if labels[label_index]==label:\n",
    "                    label_not_find = False\n",
    "                    predict = random.random()\n",
    "                    if predict<prob:\n",
    "                        item = items[label_index+1]\n",
    "                    else:\n",
    "                        if label_index==1:\n",
    "                            item = items[3]\n",
    "                        else:\n",
    "                            item = items[2]\n",
    "                else:\n",
    "                    label_index+=1 \n",
    "        else:\n",
    "            cat_index+=1\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data(node_size, train_size, folder_path):\n",
    "    label_cat = [['gender','female','male'], ['age', 'young', 'middle_age', 'old']]\n",
    "    accuracy_label_cat_1 =  [[0.8, 'gender','female','male'], [0.6, 'age', 'young', 'middle_age', 'old']]\n",
    "    accuracy_label_cat_2 =  [[0.6, 'gender','female','male'], [0.9, 'age', 'young', 'middle_age', 'old']]\n",
    "    # create user data\n",
    "    user_truth_file = folder_path+ 'user_truth.txt'\n",
    "    user_target_file = folder_path+ 'user_target.txt'\n",
    "    user_train_file = folder_path+ 'user_train.txt'\n",
    "    user_all_file = folder_path+ 'user_all.txt'\n",
    "    make_user_label_file(node_size, label_cat, train_size, user_all_file, user_truth_file, user_train_file, user_target_file)\n",
    "    # create local redictors\n",
    "    predictor_file_1 = folder_path+ 'local_predictor_1_obs.txt'\n",
    "    predictor_file_2 = folder_path+ 'local_predictor_2_obs.txt'\n",
    "    predict_1 = local_predictor('s1',accuracy_label_cat_1, user_all_file, label_cat, predictor_file_1)\n",
    "    predict_2 = local_predictor('s2',accuracy_label_cat_2, user_all_file, label_cat, predictor_file_2)\n",
    "    predictor_all_file = folder_path+ 'local_predictor_obs.txt'\n",
    "    save_file(predictor_all_file, predict_1+predict_2)\n",
    "    # create (user-user) links\n",
    "    user_link_file = folder_path+ 'friend_obs.txt'\n",
    "    create_links(node_size, user_link_file)\n",
    "    # create (user-item) likes\n",
    "    likes_label_cat = [[0.8,'gender','romance', 'action'], [0.8,'age','animation', 'drama', 'classic']]\n",
    "    likes_file = folder_path+ 'likes_obs.txt'\n",
    "    create_likes(user_all_file, likes_label_cat, label_cat, likes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_size = 10\n",
    "train_size = 6\n",
    "folder_path = '/Users/Gfarnadi/Movies/PSL_tutorial/data/'\n",
    "make_data(node_size, train_size, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_txt = '''10: Predicts(S,U,A,L)-> Is(U,A,L)^2\n",
    "10: Friend(U,V) & Is(V,A,L)-> Is(U,A,L)^2\n",
    "10: Friend(V,U) & Is(V,A,L)-> Is(U,A,L)^2\n",
    "10: Likes(U,T) & Likes(V,T) & Is(V,A,L) -> Is(U,A,L)^2\n",
    "10: Is(U,A,+L) = 1\n",
    "'''\n",
    "\n",
    "data_txt = '''predicates:\n",
    "  Predicts/4: closed\n",
    "  Friend/2: closed\n",
    "  Likes/2: closed\n",
    "  Is/3: open\n",
    "observations:\n",
    "  Predicts: data/local_predictor_obs.txt\n",
    "  Friend: data/friend_obs.txt\n",
    "  Likes : data/likes_obs.txt\n",
    "  Is : data/user_train.txt\n",
    "targets: \n",
    "  Is : data/user_target.txt\n",
    "truth: \n",
    "  Is : data/user_truth.txt\n",
    "'''\n",
    "model_path = '../model/user_modeling.psl'\n",
    "data_path =  '../model/user_modeling.data'\n",
    "save_file(model_path,model_txt)\n",
    "save_file(data_path,data_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
