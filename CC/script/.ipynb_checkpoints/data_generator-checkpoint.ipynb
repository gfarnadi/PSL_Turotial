{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os,random,networkx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file(path, content):\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    with open(path, 'a') as out:\n",
    "        out.write(content+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lines(file_path):\n",
    "    array = []\n",
    "    with open(file_path, \"r\") as ins:\n",
    "        for line in ins:\n",
    "            line = line.replace(\"\\n\",\"\")\n",
    "            if len(line)>0:\n",
    "                array.append(line)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_user_label_file(node_size, label_cat, train_size, user_all_file, user_truth_file, user_train_file, user_target_file, user_network, homophily_probability, no_prob):\n",
    "    colored_users = {}\n",
    "    colored_keys = []\n",
    "    max_counter = {}\n",
    "    i=0\n",
    "    while i<node_size:\n",
    "        net = user_network[i]\n",
    "        max_counter[i] = homophily_probability * len(net)\n",
    "        i+=1\n",
    "    if homophily_probability==0.5:\n",
    "        make_user_files(node_size, label_cat, train_size, user_all_file, user_truth_file, user_train_file, user_target_file)\n",
    "    else:\n",
    "        for label in label_cat:  \n",
    "            label_size = len(label)\n",
    "            index = 1\n",
    "            while index < label_size:\n",
    "                user_index = 0\n",
    "                while user_index in colored_users.keys():\n",
    "                    user_index = random.randint(1, node_size)-1  \n",
    "                #print(user_index)\n",
    "                colored_users[user_index] = (label[0], label[index])\n",
    "                colored_keys.append(user_index)\n",
    "                index+=1\n",
    "            # use user network based on the probability to label the nodes\n",
    "        notEmpty = True\n",
    "        while notEmpty:\n",
    "            empty = 0\n",
    "            if len(colored_users.keys())==node_size:\n",
    "                notEmpty = False\n",
    "            else:\n",
    "                temp = []\n",
    "                for user in colored_users.keys():\n",
    "                    if user in colored_keys:\n",
    "                        pass\n",
    "                    else:\n",
    "                        temp.append(user)\n",
    "                colored_keys = []\n",
    "                colored_keys = temp\n",
    "                for user in colored_keys:\n",
    "                    network = user_network[user]\n",
    "                    uncolored_users = []\n",
    "                    for friend in network:\n",
    "                        if friend in colored_keys:\n",
    "                            pass\n",
    "                        else:\n",
    "                            uncolored_users.append(friend)\n",
    "                    if len(uncolored_users) ==0:\n",
    "                        empty+=1\n",
    "                    else:\n",
    "                        color_label = colored_users[user][1]\n",
    "                        #print(user)\n",
    "                        #print(color_label)\n",
    "                        for uncolor_u in uncolored_users:\n",
    "                            if no_prob:\n",
    "                                predict = random.random() \n",
    "                                if predict>homophily_probability:\n",
    "                                    index = 1\n",
    "                                    while label[index]==color_label:\n",
    "                                        index+=1\n",
    "                                    color_label = label[index]\n",
    "                                colored_users[uncolor_u] = (label[0], color_label)\n",
    "                            else:\n",
    "                                if max_counter[user]>0:\n",
    "                                    colored_users[uncolor_u] = (label[0], color_label)\n",
    "                                    max_counter[user]=-1\n",
    "                                else:\n",
    "                                    index = 1\n",
    "                                    while label[index]==color_label:\n",
    "                                        index+=1\n",
    "                                    color_label = label[index]\n",
    "                                    colored_users[uncolor_u] = (label[0], color_label)\n",
    "            if empty==node_size:\n",
    "                notEmpty = False\n",
    "        save_user_color(colored_users, label_cat, train_size, user_train_file, user_truth_file, user_target_file,user_all_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_user_files(node_size, label_cat, train_size, user_all_file, user_truth_file, user_train_file, user_target_file):\n",
    "    user_train = ''\n",
    "    user_truth = ''\n",
    "    user_target = ''\n",
    "    user_all = ''\n",
    "    for i in range (node_size):\n",
    "        for label in label_cat:\n",
    "            label_size = len(label)\n",
    "            index = random.randint(1, label_size-1)\n",
    "            user_all+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[index]+'\\n'\n",
    "            if i>train_size:\n",
    "                j=1\n",
    "                while j<label_size:\n",
    "                    if j==index:\n",
    "                        user_truth+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[index]+'\\t'+'1.0'+'\\n'\n",
    "                    else:\n",
    "                        user_truth+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[j]+'\\t'+'0.0'+'\\n'\n",
    "                    user_target+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[j]+'\\n'\n",
    "                    j+=1\n",
    "            else:\n",
    "                j=1\n",
    "                while j<label_size:\n",
    "                    if j==index:\n",
    "                        user_train+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[index]+'\\t'+'1.0'+'\\n' \n",
    "                    else:\n",
    "                        user_train+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[j]+'\\t'+'0.0'+'\\n' \n",
    "                    j+=1\n",
    "    save_file(user_train_file, user_train)\n",
    "    save_file(user_truth_file, user_truth)\n",
    "    save_file(user_target_file, user_target)\n",
    "    save_file(user_all_file, user_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_user_color(colored_users, label_cat, train_size, user_train_file, user_truth_file, user_target_file,user_all_file):\n",
    "    user_train = ''\n",
    "    user_truth = ''\n",
    "    user_target = ''\n",
    "    user_all = ''\n",
    "    for i in range (node_size):\n",
    "        label = colored_users[i]\n",
    "        cat = find_cat(label[0], label_cat)\n",
    "        label_size = len(cat)\n",
    "        user_all+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[1]+'\\n'\n",
    "        if i>train_size:\n",
    "            j=1\n",
    "            while j<label_size:\n",
    "                if label[1]==cat[j]:\n",
    "                    user_truth+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[1]+'\\t'+'1.0'+'\\n' \n",
    "                else:\n",
    "                    user_truth+= 'u'+str(i)+'\\t'+label[0] +'\\t'+cat[j]+'\\t'+'0.0'+'\\n'\n",
    "                user_target+= 'u'+str(i)+'\\t'+label[0] +'\\t'+cat[j]+'\\n'\n",
    "                j+=1\n",
    "        else:\n",
    "            j=1\n",
    "            while j<label_size:\n",
    "                if label[1]==cat[j]:\n",
    "                    user_train+= 'u'+str(i)+'\\t'+label[0] +'\\t'+label[1]+'\\t'+'1.0'+'\\n' \n",
    "                else:\n",
    "                    user_train+= 'u'+str(i)+'\\t'+label[0] +'\\t'+cat[j]+'\\t'+'0.0'+'\\n' \n",
    "                j+=1\n",
    "    save_file(user_train_file, user_train)\n",
    "    save_file(user_truth_file, user_truth)\n",
    "    save_file(user_target_file, user_target)\n",
    "    save_file(user_all_file, user_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cat(user_cat, label_cat):\n",
    "    i = 0\n",
    "    result = []\n",
    "    while i< len(label_cat):\n",
    "        cat = label_cat[i]\n",
    "        if user_cat == cat[0]:\n",
    "            result = cat\n",
    "            i=len(label_cat)\n",
    "        else:\n",
    "            i+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_predictor(source, accuracy_label_cat, user_label_file, label_cat_info, predictor_file, no_prob):\n",
    "    lines1 = read_lines(user_label_file)\n",
    "    user_txt = ''\n",
    "    max_counter = {}\n",
    "    lines = np.random.permutation(lines1)\n",
    "    for cat in accuracy_label_cat:\n",
    "        max_counter[cat[1]] = float(cat[0])*len(lines)\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        user = info[0]\n",
    "        cat = info[1]\n",
    "        label = info[2]\n",
    "        label_cat, accuracy = find_label_cat(accuracy_label_cat, cat, label, label_cat_info)\n",
    "        max_counter[cat] -=1\n",
    "        if no_prob:\n",
    "            predict = random.random() \n",
    "            if predict>accuracy:\n",
    "                index = 1\n",
    "                while label_cat[index]==label:\n",
    "                    index+=1\n",
    "                label = label_cat[index]\n",
    "            user_txt+= source+'\\t'+user+'\\t'+label_cat[0]+ '\\t'+label+'\\t'+'1.0'+'\\n'\n",
    "        else:\n",
    "            if max_counter[cat]>0:\n",
    "                user_txt+= source+'\\t'+user+'\\t'+label_cat[0]+ '\\t'+label+'\\t'+'1.0'+'\\n'\n",
    "            else:\n",
    "                index = 1\n",
    "                while label_cat[index]==label:\n",
    "                    index+=1\n",
    "                label = label_cat[index]\n",
    "                user_txt+= source+'\\t'+user+'\\t'+label_cat[0]+ '\\t'+label+'\\t'+'1.0'+'\\n'\n",
    "    save_file(predictor_file, user_txt)\n",
    "    return user_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_label_cat(accuracy_label_cat, cat, label, label_cat_info):\n",
    "    notFind = True\n",
    "    index = 0\n",
    "    while notFind:\n",
    "        info = accuracy_label_cat[index]\n",
    "        if info[1]==cat:\n",
    "            notFind = False\n",
    "            accuracy = info[0]\n",
    "            label_cat = label_cat_info[index]\n",
    "        else:\n",
    "            index+=1\n",
    "    return label_cat, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_links(node_size, user_link_file):\n",
    "    link_txt = ''\n",
    "    edges = create_synthetic_graph(node_size)\n",
    "    for edge in edges:\n",
    "        link_txt+= 'u'+str(edge[0])+'\\t'+'u'+str(edge[1])+'\\t'+'1.0'+'\\n'\n",
    "    save_file(user_link_file, link_txt)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_synthetic_graph(node_size):\n",
    "    m = 6\n",
    "    p = 0.3 \n",
    "    graph = networkx.powerlaw_cluster_graph(node_size, m, p, seed=None)\n",
    "    return graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_likes(user_label_file, likes_label_cat, label_cat, likes_file, no_prob):\n",
    "    lines1 = read_lines(user_label_file)\n",
    "    likes_txt = ''\n",
    "    max_counter = {}\n",
    "    lines = np.random.permutation(lines1)\n",
    "    for cat in likes_label_cat:\n",
    "        max_counter[cat[1]] = float(cat[0])*len(lines)\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        user = info[0]\n",
    "        cat = info[1]\n",
    "        label = info[2]\n",
    "        item = get_item(likes_label_cat,label_cat, cat, label, max_counter, no_prob)\n",
    "        likes_txt += user+'\\t'+item+'\\t'+'1.0'+'\\n'\n",
    "    save_file(likes_file, likes_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(edges):\n",
    "    user_network = {}\n",
    "    for edge in edges:\n",
    "        if edge[0] in user_network.keys():\n",
    "            friends_0 = user_network[edge[0]]\n",
    "            friends_0.append(edge[1])\n",
    "        else:\n",
    "            user_network[edge[0]] = [edge[1]]\n",
    "        if edge[1] in user_network.keys():\n",
    "            friends_0 = user_network[edge[1]]\n",
    "            friends_0.append(edge[0])\n",
    "        else:\n",
    "            user_network[edge[1]] = [edge[0]]\n",
    "    return user_network   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item(likes_label_cat, label_cat, cat, label, max_counter, no_prob):\n",
    "    notFind = True\n",
    "    cat_index = 0\n",
    "    item = ''\n",
    "    while notFind:\n",
    "        items = likes_label_cat[cat_index]\n",
    "        if items[1]==cat:\n",
    "            prob = items[0]\n",
    "            notFind = False\n",
    "            label_index = 1\n",
    "            label_not_find = True\n",
    "            labels = label_cat[cat_index]\n",
    "            while label_not_find:\n",
    "                if labels[label_index]==label:\n",
    "                    label_not_find = False\n",
    "                    predict = random.random()\n",
    "                    if no_prob:\n",
    "                        if predict<prob:\n",
    "                            item = items[label_index+1]\n",
    "                        else:\n",
    "                            if label_index==1:\n",
    "                                item = items[3]\n",
    "                            else:\n",
    "                                item = items[2]\n",
    "                    else:\n",
    "                        if max_counter[cat]>0:\n",
    "                            item = items[label_index+1]\n",
    "                            max_counter[cat]-=1\n",
    "                        else:\n",
    "                            if label_index==1:\n",
    "                                item = items[3]\n",
    "                            else:\n",
    "                                item = items[2]\n",
    "                            \n",
    "                else:\n",
    "                    label_index+=1 \n",
    "        else:\n",
    "            cat_index+=1\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_source(node_size, source, source_file):\n",
    "    text = ''\n",
    "    for i in range (node_size):\n",
    "        for s in source:\n",
    "            text+= 'u'+str(i)+'\\t'+s+'\\t'+'1.0'+'\\n'\n",
    "    save_file(source_file,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data(node_size, train_size, folder_path):\n",
    "    #label_cat = [['gender','female','male'], ['age', 'young', 'middle_age', 'old']]\n",
    "    label_cat = [['personality','ext','int']]\n",
    "    #accuracy_label_cat_1 =  [[0.8, 'gender','female','male'], [0.7, 'age', 'young', 'middle_age', 'old']]\n",
    "    #accuracy_label_cat_2 =  [[0.7, 'gender','female','male'], [0.8, 'age', 'young', 'middle_age', 'old']]\n",
    "    accuracy_label_cat_1 =  [[0.75, 'personality','ext','int']]\n",
    "    accuracy_label_cat_2 =  [[0.65, 'personality','ext','int']]\n",
    "    # create user data\n",
    "    user_truth_file = folder_path+ 'user_truth.txt'\n",
    "    user_target_file = folder_path+ 'user_target.txt'\n",
    "    user_train_file = folder_path+ 'user_train.txt'\n",
    "    user_all_file = folder_path+ 'user_all.txt'\n",
    "    # create (user-user) links\n",
    "    user_link_file = folder_path+ 'friend_obs.txt'\n",
    "    edges = create_links(node_size, user_link_file)\n",
    "    user_network = make_network(edges)\n",
    "    homophily_probability = 0.9\n",
    "    make_user_label_file(node_size, label_cat, train_size, user_all_file, user_truth_file, user_train_file, user_target_file, user_network, homophily_probability, True)\n",
    "    # create local redictors\n",
    "    predictor_file_1 = folder_path+ 'local_predictor_1_obs.txt'\n",
    "    predictor_file_2 = folder_path+ 'local_predictor_2_obs.txt'\n",
    "    predict_1 = local_predictor('txt',accuracy_label_cat_1, user_all_file, label_cat, predictor_file_1, False)\n",
    "    predict_2 = local_predictor('img',accuracy_label_cat_2, user_all_file, label_cat, predictor_file_2, False)\n",
    "    source_file = folder_path+ 'has_obs.txt'\n",
    "    source = ['txt', 'img']\n",
    "    save_source(node_size, source, source_file)\n",
    "    predictor_all_file = folder_path+ 'local_predictor_obs.txt'\n",
    "    save_file(predictor_all_file, predict_1+predict_2)\n",
    "    # create (user-item) likes\n",
    "    #likes_label_cat = [[0.7,'gender', 'romance', 'action'], [0.7,'age', 'animation', 'drama', 'classic']]\n",
    "    likes_label_cat = [[0.7,'personality','action','anim']]\n",
    "    likes_file = folder_path+ 'likes_obs.txt'\n",
    "    Join_label_cat = [[0.8,'personality', 'party', 'video-game']]\n",
    "    joins_file = folder_path+ 'joins_obs.txt'\n",
    "    create_likes(user_all_file, likes_label_cat, label_cat, likes_file, False)\n",
    "    create_likes(user_all_file, Join_label_cat, label_cat, joins_file, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_size = 100\n",
    "train_size = 6\n",
    "folder_path = '../data/'\n",
    "make_data(node_size, train_size, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_txt = '''//1: Has(U,S) & Predicts(S,U,A,L)-> Is(U,A,L)^2\n",
    "//1: Has(U,S) & ~Predicts(S,U,A,L)-> ~Is(U,A,L)^2\n",
    "1: Friend(U,V) & Is(V,A,L)-> Is(U,A,L)^2\n",
    "1: Friend(V,U) & Is(V,A,L)-> Is(U,A,L)^2\n",
    "1: Friend(U,V) & ~Is(V,A,L)-> ~Is(U,A,L)^2\n",
    "1: Friend(V,U) & ~Is(V,A,L)-> ~Is(U,A,L)^2\n",
    "//1: Likes(U,T) & Likes(V,T) & Is(V,A,L) -> Is(U,A,L)^2\n",
    "//1: Likes(U,T) & Likes(V,T) & ~Is(V,A,L) -> ~Is(U,A,L)^2\n",
    "//1: Joins(U,G) & Joins(V,G) & Is(V,A,L) -> Is(U,A,L)^2\n",
    "//1: Joins(U,G) & Joins(V,G) & ~Is(V,A,L) -> ~Is(U,A,L)^2\n",
    "1: Is(U,A,+L) = 1\n",
    "'''\n",
    "\n",
    "data_txt = '''predicates:\n",
    "  Predicts/4: closed\n",
    "  Friend/2: closed\n",
    "  Likes/2: closed\n",
    "  Joins/2: closed\n",
    "  Has/2: closed\n",
    "  Is/3: open\n",
    "observations:\n",
    "  Predicts: ../data/local_predictor_obs.txt\n",
    "  Has: ../data/has_obs.txt\n",
    "  Friend: ../data/friend_obs.txt\n",
    "  Likes : ../data/likes_obs.txt\n",
    "  Joins : ../data/joins_obs.txt\n",
    "  Is : ../data/user_train.txt\n",
    "targets: \n",
    "  Is : ../data/user_target.txt\n",
    "truth: \n",
    "  Is : ../data/user_truth.txt\n",
    "'''\n",
    "model_path = '../model/user_modeling.psl'\n",
    "data_path =  '../model/user_modeling.data'\n",
    "save_file(model_path,model_txt)\n",
    "save_file(data_path,data_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
